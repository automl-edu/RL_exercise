\documentclass{exam}
\usepackage{amsmath, amsfonts}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage[super]{nth}

\DeclareMathOperator*{\argmin}{argmin}

\usepackage[hyperfootnotes=false]{hyperref}

\usepackage[usenames,dvipsnames]{color}
\newcommand{\note}[1]{
	\noindent~\\
	\vspace{0.25cm}
	\fcolorbox{Red}{Orange}{\parbox{0.99\textwidth}{#1\\}}
	%{\parbox{0.99\textwidth}{#1\\}}
	\vspace{0.25cm}
}


%\input{../macros}
%\renewcommand{\hide}[1]{#1}

\qformat{\thequestion. \textbf{\thequestiontitle}\hfill}
\bonusqformat{\thequestion. \textbf{\thequestiontitle}\hfill}

\pagestyle{headandfoot}

%%%%%% MODIFY FOR EACH SHEET!!!! %%%%%%
\newcommand{\duedate}{24.11.2021 (15:00)}
\newcommand{\due}{{\bf This assignment is due on \duedate.} }
\firstpageheader
{Due: \duedate}
{{\bf\lecture}\\ \assignment{1}}
{\lectors\\ \semester}

\runningheader
{Due: \duedate}
{\assignment{1}}
{\semester}
%%%%%% MODIFY FOR EACH SHEET!!!! %%%%%%

\firstpagefooter
{}
{\thepage}
{}

\runningfooter
{}
{\thepage}
{}

\headrule
\pointsinrightmargin
\bracketedpoints
\marginpointname{pt.}


\begin{document}

\noindent
Complete the exercises and record your observations in the \emph{observations.txt} file.

\begin{questions}
	\titledquestion{Tabular Q-Learning}
	Implement the Q-Learning update step in \emph{q\_learning\_tabular.py} and try different state discretizations (\texttt{BINS}) and learning rates (\texttt{LEARNING\_RATE}). How does the number of states and learning rate affect the training of the RL algorithm?
	\titledquestion{Q-Learning with Value Function Approximation}
	Implement the value function training step in \emph{q\_learning\_vfa.py} using the \texttt{Q} module and the \texttt{optimizer}. How does the training differ from the tabular case? How sensitive is the algorithm to the weight initialization?
\end{questions}

\end{document}