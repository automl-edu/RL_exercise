\documentclass{exam}
\usepackage{amsmath, amsfonts}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage[super]{nth}

\DeclareMathOperator*{\argmin}{argmin}

\usepackage[hyperfootnotes=false]{hyperref}

\usepackage[usenames,dvipsnames]{color}
\newcommand{\note}[1]{
	\noindent~\\
	\vspace{0.25cm}
	\fcolorbox{Red}{Orange}{\parbox{0.99\textwidth}{#1\\}}
	%{\parbox{0.99\textwidth}{#1\\}}
	\vspace{0.25cm}
}

\qformat{\thequestion. \textbf{\thequestiontitle}\hfill}
\bonusqformat{\thequestion. \textbf{\thequestiontitle}\hfill}

\pagestyle{headandfoot}

%%%%%% MODIFY FOR EACH SHEET!!!! %%%%%%
\newcommand{\duedate}{01.12.2021 (15:00)}
\newcommand{\due}{{\bf This assignment is due on \duedate.} }
\firstpageheader
{Due: \duedate}
{{\bf\lecture}\\ \assignment{1}}
{\lectors\\ \semester}

\runningheader
{Due: \duedate}
{\assignment{1}}
{\semester}
%%%%%% MODIFY FOR EACH SHEET!!!! %%%%%%

\firstpagefooter
{}
{\thepage}
{}

\runningfooter
{}
{\thepage}
{}

\headrule
\pointsinrightmargin
\bracketedpoints
\marginpointname{pt.}


\begin{document}

\begin{questions}
	\titledquestion{Deep Q Learning}
	\indent
	\begin{itemize}
		\item Implement the Deep Q-Network (DQN) in \emph{deep\_q\_learning.py}. Try to vary the DQN architecture (wider, deeper) and record your observations.
		\item Add a replay buffer to solve the \texttt{LunarLander-v2} environment.
		 How does the replay buffer size affect training performance?
	\end{itemize}
	
\end{questions}

\end{document}